\begin{shadequote}[r]{해들리 위컴(Hadley Wickham)}
저의 바람은 R과 Python의 통합이 계속 발전하여 R이 데이터 과학 작업흐름에 더욱 원활하게 적용되는 것입니다.(My hope is that the integrations between R and Python continue to grow and for R to more seamlessly fit in the data science workflow.)
\end{shadequote}

# 환경설정

챗GPT와 유닉스 쉘에서 필요한 도구와 실습에 필요한 데이터를 소개한다.
컴퓨터를 활용할 수 있는 다양한 패러다임이 도입되고 이를 뒷받침하는 도구들이 
개발되면서 동일한 작업을 효율적으로 더 빠르고 수월히 할 수 있게 되었다.

먼저, 유닉스 쉘은 리눅스 혹은 맥OS 운영체제를 채택한 컴퓨터에는 기본 설치되어 있다.
문제는 윈도우다. 윈도우에서 유닉스 운영체제를 사용하는 방법은 리눅스를 윈도우 스토어에서 
통상 WSL(Windows Subsystem for Linux, 리눅스용 윈도우즈 하위시스템)로 알려진 앱처럼 설치하여 사용하는 방법이고, 다른 방식은 깃 배쉬(Git Bash)를 설치하여 에뮬레이터처럼 가볍게 사용하는 방식으로 `make`등 일부 기능은 기본기능으로 제공이 되는다.

유닉스 쉘을 주로 데이터 과학업무 자동화를 통한 생산성 향상에 방점을 두고 집필이 이뤄지다보니 실습 예제 데이터가 필수적이다. 소프트웨어 카펜트리에서 수십년 동안 검증된 유닉스 쉘 워크샵 데이터를 사용하여 실습데이터도 준비한다.

마지막으로 챗GPT도 실습에 준비를 한다. 유닉스 쉘 취지에 맞춰 개발자가 복사하여 붙여넣는 방식은 지양하고 OpenAI 챗GPT API\footnote{API (Application Programming Interface)는 서로 다른 소프트웨어 간에 정보를 주고 받기 위한 규칙이나 표준을 정의한 것이다. 한 프로그램이 다른 프로그램의 기능을 사용하게 해주는 '다리'와 같은 역할을 한다.}를 사용한다. 한 걸음 더 나아가 챗GPT가 생성한 유닉스 명령어도 복사하여 붙여넣는 방식을 지양하고 즉각 실행하여 결과를 확인할 수 있도록 ShellGPT를 챗GPT와 유닉스 쉘을 연결하도록 설정한다.


```{r}
#| echo: false
library(reticulate)

use_condaenv(condaenv = 'gpt-shell')
```

## 챗GPT 연동

챗GPT는 OpenAI에서 개발한 AI 대화 도구로, GPT (Generative Pre-training Transformer)라는 학습 모델을 바탕으로 한다. GPT는 '생성 전이 학습'이라는 방법을 사용하여 수많은 책, 웹페이지, 기사 등의 텍스트를 읽고 사람처럼 언어를 이해하고 사용하는 법을 학습한다. 이 과정을 통해, 챗GPT는 사람이 사용하는 다양한 표현법과 문법을 파악하고, 그것을 활용해 대화를 할 수 있게 되었고, 창의적 글쓰기부터 요약, 번역, 개체명 추출, 코딩 등의 기능성 작업에 이르기까지 다양한 종류의 글쓰기를 처리할 수 있다. 또한, 간단한 사실 확인에서 복잡한 주제에 대한 토론까지 다양한 질문에 대한 답변을 생성해낼 수 있다.


OpenAI\index{OpenAI} GPT 제품은 파이썬이 주 개발언어로 되어 있어 
파이썬을 기준으로 챗GPT 개발을 진행한다.

API를 활용한 파이썬 개발작업흐름은 먼저, 1)가상환경을 구축하
고, 2)API KEY를 발급받고 3)해당 `openai`\index{openai} 패키지를 설치하고 
4)헬로월드를 찍고 5)본격적인 AI 제품 개발을 진행하는 방식으로 추진한다.


```{mermaid}
graph LR
  A["1. 가상환경<br>구축"] --> B["2. API KEY<br>발급/설정"]
  B --> C["3. openai <br>패키지 설치"]
  C --> D["4. 헬로월드"]
  
  style A fill:#f9d5e5,stroke:#333,stroke-width:2px
  style B fill:#eeac99,stroke:#333,stroke-width:2px
  style C fill:#e06377,stroke:#333,stroke-width:2px
  style D fill:#c83349,stroke:#333,stroke-width:2px
  classDef default fill:#f9f7f7,stroke:#333,stroke-width:2px;
```


### 가상환경 설정

파이썬의 가장 큰 장점이자 단점은 동일한 기능을 사용하는 수많은 패키지가 존재한다는 점이다.
의존성을 낮추고 격리된 개발환경을 지향하는 가상환경도 예외는 아니다.
파이썬 가상환경 중에 많이 알려진 도구로 파이썬 3.3 버전부터 별도 설치없이 내장되어 제공되는 `venv`\index{venv}, 많이 사용되는 `virtualenvwrapper`, `virtualenv` 등이 잘 알려져 있다.
본인 취향에 맞는 가상환경을 특정하여 업무에 사용한다. 다음은 `venv`를 사용해서 가상 개발환경을 구축하는 것을 예시로 보여주고 있다.

```bash
## 디렉토리 생성 및 프로젝트 디렉토리 이동
mkdir myproject
cd myproject

## 가상환경 생성
python -m venv myenv

## 가상환경 활성화
myenv\Scripts\activate # 윈도우즈
source myenv/bin/activate # 리눅스/맥

## 가상환경 비활성화
deactivate
```

### API KEY 발급

가상환경을 구축한 다음 OpenAI에서 제공하는 공식 API에 접근할 수 있는 API 키를 생성하는 것이다.
https://platform.openai.com/apps [^openai-api] 로 이동하여 계정을 만듭니다.

[^openai-api]: <https://platform.openai.com/apps>

안내에 따라 계정을 생성한 다음 https://platform.openai.com/account/api-keys [^openai-api-key] 로 이동하여 API 키를 생성한다.

[^openai-api-key]: <https://platform.openai.com/account/api-keys>

API 키는 조직에 속해야 하며, 조직을 생성하라는 메시지가 표시되는 경우 조직명을 입력한다.
하나의 조직에 속한 경우 조직 ID(Organization ID)를 별도 생성할 필요는 없다.
OpenAI 계정을 통해서는 생성한 API KEY\index{API Key}는  다시 볼 수 없기 때문에 생성한 비밀 키를 안전하고 접근하기 쉬운 곳에 저장한다. 

### API KEY 설정

API KEY를 환경변수로 지정하여 호출하는 방식도 있고,
작업 프로젝트 디렉토리에 로컬 파일에 저장하여 사용하는 방식도 있다.
먼저 윈도우에서 `시스템`으로 들어가서 `환경 변수`로 지정하면 해당 변수(`OPENAI_API_KEY`)를 
다양한 프로그램에서 호출하여 사용할 수 있다.

![](images/openai_api_export.jpg)

혹은 윈도우즈 쉘 프로그램 `cmd`를 실행한 후 다음 명령어를 실행시키게 되면 `OPENAI_API_KEY`가
환경변수로 등록되어 API 호출시 인증값으로 사용할 수 있다.


```bash
C:\Users\tidyverse> setx OPENAI_API_KEY “sk-hDxxxxxxxxxxxxxxxxxxxxx”
```

제대로 `OPENAI_API_KEY`에 값이 할당되었는지 확인은 `echo %OPENAI_API_KEY%` 명령어를 실행한다.

```bash
C:\Users\tidyverse> echo %OPENAI_API_KEY%
sk-hDxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

맥에서도 유사한 방식으로 설정할 수 있다. 앞서 학습한 유닉스 쉘 명령어를 사용하여 `.bashrc` 파일에 `OPENAI_API_KEY`를 추가한다. 그리고 `source` 명령어로 `OPENAI_API_KEY` 반영사항을 적용시킨다.
제대로 환경설정이 되었는지 `echo` 명령어로 `OPENAI_API_KEY` 값을 확인한다.

```bash
$ echo "export OPENAI_API_KEY='sk-hDxxxxxxxxxxxxxxxxxxxx'" >> ~/.bashrc
$ source ~/.bashrc
$ echo $OPENAI_API_KEY
sk-hDxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

`OPENAI_API_KEY`를 운영체제에 등록하는 방식은 운영체제가 달라짐에 따라 매번 변
경을 해야하는 번거러운 점이 있다. 운영체제가 아닌 프로젝트 단위에서 API 호출 `OPENAI_API_KEY`를 사용하게 되면 문제를 해결할 수 있다. 하지만 프로젝트 단위에서 파일에 `OPENAI_API_KEY`를 관리하는 경우 주의가 요구된다.

프로젝트 단위로 `OPENAI_API_KEY`를 관리하는 방식은 `.env`\index{.evn}와 같은 파일을 프로젝트 디렉토리 아래 숨긴 파일에 지정하여 사용하는 방식이다. `.env` 파일은 보통 프로젝트 루트 디렉토리에 파일형태로 저장시키는 것이 일반적이다.  특히 깃(Git) 혹은 다른 버전제어 도구와 함께 국내외 개발자와 협업하여 프로젝트를 진행하는 경우 외부에 노출되는 문제가 발생할 수 있다. 이런 경우 `.gitignore`\index{.gitignore} 파일에 버전제어 대상에서 제외시켜 두는 것을 필히 기억한다.

![](images/openai_api_file.jpg)


### `openai` 설치

`pip install` 명령어로 `openai` 파이썬 패키지를 설치한다.
파이썬이 아닌 R의 경우도 `install.packages('openai')` 패키지를 사용하여 챗GPT API를 등록된 `OPENAI_API_KEY`를 사용하여 활용이 가능하다.

```bash
$ pip install openai
```

:::{.callout-note}
### Command 'pip' not found

`$ pip install openai`를 위해서는 `pip` 파이썬 패키지 관리 프로그램이 설치되어야한다.
`Command 'pip' not found` 오류가 발생된 경우 당황하지 말고 안내에 따라
`python3-pip` 패키지를 먼저 설치한다.

```bash
$ pip install openai
Command 'pip' not found, but can be installed with:
sudo apt install python3-pip

$ sudo apt install python3-pip
```

:::



### 헬로월드

OpenAI API KEY도 준비가 되었으면 헬로월드 프로그램을 작성해보자.
개발자가 하나의 조직에 속한 경우, API KEY를 운영체제 환경변수로 지정한 경우
다음과 같이 시스템 환경에서 `OPENAI_API_KEY` 키를 가져와서 OpenAI에서 제공하는 
모델목록을 확인할 수 있다.

```{python}
#| eval: true
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

# API 호출 및 모델 목록 출력
models = openai.Model.list()
print(models['data'][0])
```

다른 방식은 로컬 파일에 API KEY와 ORG ID 를 저장하고 이를 불러와서 개발에 사용하는 방식이다.

```{python}
#| eval: true
import os
import openai

# .env 파일에서 API_KEY 와 ORG_ID 을 읽어온다.
with open(".env") as lines:
  for line in lines:
    key, value = line.strip().split("=")
    os.environ[key] = value
    
# api_key와 organization 지정
openai.api_key = os.environ.get("API_KEY")
openai.organization = os.environ.get("ORG_ID")

# API 호출 및 모델 목록 출력
gpt_models = openai.Model.list()

print(gpt_models['data'][0])
```

### OpenAI 모형

OpenAI에서 제공하는 다양한 모델을 확인할 수 있다.
`system`이 소유한 GPT 모형을 살펴보자. 파이썬이 `openai` 패키지를 통해
OpenAI 거대언어모형(LLM)을 비롯한 이미지(Dall·e 2), 오디오(Whisper) 등 다양한 AI 모형을 제공하고 있지만 출판수준 고품질 표를 제작하는데는 R 언어 및 패키지가 유용하다.
먼저 파이썬과 R을 연결하는데 `reticulate` 패키지를 `install.packages()` 함수로 설치하고 R `tidyverse` 패키지도 설치한다. `tidyverse` `dplyr` 패키지로 파이썬에서 넘어온 AI 모형
데이터를 전처리하고 표문법 `gt` 및 `gtExtras` 패키지로 깔끔한 표를 제작한다.

```{r}
# install.packages(c("reticulate", "tidyverse"))

library(reticulate)
library(tidyverse)

py_gpt_models <- py$gpt_models$data

gpt_models_tbl <- tibble(created = map_chr(py_gpt_models, "created"),
                         id = map_chr(py_gpt_models, "id"),
                         object = map_chr(py_gpt_models, "object"),
                         owned_by = map_chr(py_gpt_models, "owned_by")) %>% 
  mutate(created = anytime::anydate(as.integer(created))) %>% 
  arrange(desc(created)) 
```

프로그램 코드(`code`) 관련된 GPT 모형도 확인할 수 있다.

```{r}
gpt_models_tbl %>% 
  filter(str_detect(id, "code")) %>% 
  gt::gt() %>% 
  gtExtras::gt_theme_nytimes()
```

## 윈도우 쉘 환경

윈도우 운영체제에서 유닉스 쉘(Shell)을 사용하는 방법은 여러 가지다. 윈도우 운영체제에 내장된 명령 프롬프트(`cmd.exe`)는 OS/2, 윈도우 임베디드, 윈도우 NT 5.0 이상 기반 시스템의 명령어 인터프리터로 잘 알려져 있다. 최근에는 마이크로소프트가 개발한 파워쉘(PowerShell)이라는, 확장 가능한 명령 줄 인터페이스 쉘 및 스크립트 언어를 특징으로 하는 명령어 인터프리터도 주목받고 있다. 하지만, 이런 `cmd`\index{cmd}, `PowerShell`\index{PowerShell}은 윈도우 운영체제에서만 작동한다는 한계가 있다. 맥과 리눅스, 특히 클라우드를 지배하고 있는 유닉스 쉘을 윈도우에서도 무리없이 사용할 수 있다면, 모든 운영체제에서 공통 작업을 수행하는 데 큰 도움이 될 것이다. 이를 위해 WSL(Windows SubSystem for Linux)를 통해 다양한 리눅스 운영체제를 설치할 수 있으며, Git Bash\footnote{https://git-scm.com/downloads}를 설치하여 윈도우에서도 유닉스 쉘을 활용할 수 있다.


### WSL

WSL(Linux용 Windows 서브시스템)\index{WSL}을 통해 우분투(Ubuntu)\index{WSL!Ubuntu}\index{WSL!우분투}, 데비안(Debian)\index{WSL!Debian}\index{WSL!데비안}를 포함한 다양한 리눅스 배포판을 설치할 수 있다. 여기서 데비안를 설치하는 경우를 살펴보자. 기본적인 작업흐름은 다른 리눅스 배포판 설치와 동일한데 먼저 WSL을 설치하고 이어서 데비안 리눅스 배포판을 설치한다.

윈도우즈 PowerShell을 통해 WSL(Linux용 Windows 하위 시스템)을 설치한다.

```bash
$ wsl --install
```

상기 명령을 실행하면 시스템이 WSL과 Linux 배포판(기본값은 우분투)을 설치하고 PC를 재시작한다.

'가상 머신 플랫폼' 선택적 구성 요소를 활성화시킨다. 새 Linux 배포판을 설치하기 전
에 '가상 머신 플랫폼' 구성 요소가 활성화되어 있는지 확인해야 하고, 관리자 권한으로
PowerShell을 다시 열고 실행한다. 보통 화면 아래 왼쪽 구석에 있는 윈도우 아이콘 옆에 있는 돋보기 아이콘의 검색기능을 선택하고, "powershell"을 입력하여 찾는다. 그리고 관리자로 실행"을 찾아 선택한다.


```bash
$ dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart
```

PC를 다시 시작하여 WSL 설치 및 WSL 2로 업데이트를 완료하고, WSL 2를 기본 버전으로 설정한다.

```bash
$ wsl --set-default-version 2
```

`wsl --install` 디폴트로 우분투 리눅스 배포판이 설치되지만
`-d Debian` 인자를 넣게 되면 데비안 리눅스 배포판을 설치할 수 있다.

```bash
$ wsl --install -d Debian
```

Debian을 설치하는 과정에서 아래 부분에 추가 입력이 필요하다.

```bash
Enter new UNIX username: 
New password:
Retype new password:
```

희망하는 사용자ID과 암호를 각각 입력한다.

이후, 정상으로 WSL 데비안 배포판이 설치되었는지 확인하고자 프롬프트에 아래와 같이 입력하고 실행한다.

```bash
$ cat /etc/os-release
PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
NAME="Debian GNU/Linux"
VERSION_ID="11"
VERSION="11 (bullseye)"
VERSION_CODENAME=bullseye
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"
```

## ShellGPT (쉘GPT)

OpenAI의 챗GPT(GPT-3.5)는 콘텐츠 생성에 주된 방점이 있지만 다양한 프로그래밍 코드도 작성함은 물론 유닉스 쉘 프로그램도 작성하여 CLI\footnote{CLI(Command Line Interface)는 사용자가 키보드에 텍스트를 입력하여 컴퓨터 명령을 내리는 통신방식이다.} 생산성을 높이는데 사용될 수 있다. 챗GPT 기능을 활용하여 쉘 명령, 코드 스니펫\footnote{스니펫(snippet)은 프로그래밍에서 재사용 가능한 작은 코드 조각으로, 코드 작성을 보다 빠르고 효과적으로 하기 위한 도구로, 특히 반복적으로 사용되는 코드 패턴이나 구조를 빠르게 삽입할 때 유용하다.}, 주석, 문서 등을 생성할 수 있다. 즉, 데이터 과학자를 비롯한 개발자가 기존에 업무를 수행하던 방식이 전혀 다르게 된다. 즉, 책, 매뉴얼, 비밀노트(Cheat Sheet), 인터넷 북마크, 구글링 같은 검색없이 바로 터미널에서 바로 정확한 답변을 얻어 귀중한 시간과 노력을 절약할 수 있다. 예를 들어 앞서 프로젝트를 할 때 해당 유닉스 쉘 명령어가 기억나지 않는다고 하면 ShellGPT를 사용하여 해당 작업을 신속하게 수행할 수 있다

[ShellGPT](https://github.com/TheR1D/shell_gpt)\index{ShellGPT}\index{쉘GPT}를 사용하기 위한 환경설정 작업을 해야 한다. [ShellGPT](https://github.com/TheR1D/shell_gpt)가 파이썬으로 개발되어 WSL 데비안 혹은 우분투로 설치한 경우 다음 순서대로 설치를 진행한다.

curl\index{curl}은 다양한 통신 프로토콜을 이용하여 데이터를 전송하기 위한 라이브러리와 명령 줄 도구를 제공하는 컴퓨터 소프트웨어로 쉘에서 설치하는데 파이썬 설치파일을 전송받는데 필요하다.

```bash
$ sudo apt install curl
```

파이썬을 설치하기 위해서 `get-py.py` 파일이 필요한데 설치에 앞서 `python3-distutils` 파일을 설치한다.

```bash
$ sudo apt-get install python3-distutils
```

파이썬 설치파일을 다운로드하고 파이썬을 설치하고 `python3` 명령어를 통해 버전을 확인한다.

```bash
$ curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
$ sudo python3 get-pip.py
$ python3 --version
Python 3.9.2
```

Python 3.x\index{Python}\index{파이썬}는 Python 2.x가 설치된 시스템에서 python3로 설치되는 경우가 많으며, python 명령은 이전 버전(Python 2.x)에 링크되어 있는 경우가 많고 리눅스 배포판에서 일반적이다. Python 3.x에서 python 명령을 사용하려면 별칭(alias)을 만들어야 한다.

`nano`\index{nano} 편집기를 열고 `alias python=python3`을 추가하고 저장한다. 

```bash
$ nano ~/.bashrc
```

```
alias python=python3
```

다시 쉘에서 변경사항을 적용시키면 `python` 명령어를 실행하게 되면 `python3` 가 대신 실행되는 것을 확인할 수 있다.

```bash
$ source ~/.bashrc
$ python --version
Python 3.9.2
```

[ShellGPT](https://github.com/TheR1D/shell_gpt) 웹사이트를 참고하고 `sudo pip install shell-gpt`와 같이 버전을 특정하지 않는 경우 가장 최신 버전이 설치되고, 특정 버젼을 지정하고자 하는 경우,`shell-gpt==0.9.3`와 같이 특정한다. 서로 장단점이 있으니 독자입장에서 유익한 방향으로 설치를 권장한다.

```bash
$ sudo pip install shell-gpt==0.9.3
```

`sgpt`\index{sgpt}를 처음 실행하게 되면 OpenAI API Key를 입력해야 한다. [OpenAI](https://platform.openai.com/account/api-keys)에서 `API Keys`를 생성하여 붙여넣기 하면 `~/.config/shell_gpt/.sgptrc` 파일에 저장되어 `ShellGPT`를 사용하게 된다.

```bash
$ sgpt
Please enter your OpenAI API key:
```

`cat`\index{cat} 명령어로 `OPENAI_API_KEY`가 정상등록된 것을 확인하고 헬로월드를 보내보자.
`sgpt` 다음에 자연어로 지시사항을 보내면 `gpt-3.5-turbo` 엔진을 통해 자연어를 해석하고 이를 결과로 반환해준다.

```bash
$ cat ~/.config/shell_gpt/.sgptrc
CHAT_CACHE_PATH=/tmp/chat_cache
CACHE_PATH=/tmp/cache
CHAT_CACHE_LENGTH=100
CACHE_LENGTH=100
REQUEST_TIMEOUT=60
DEFAULT_MODEL=gpt-3.5-turbo
OPENAI_API_HOST=https://api.openai.com
DEFAULT_COLOR=magenta
ROLE_STORAGE_PATH=/home/xxxxxxxx/.config/shell_gpt/roles
SYSTEM_ROLES=false
DEFAULT_EXECUTE_SHELL_CMD=false
OPENAI_API_KEY=sk-wUxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxFf
$ sgpt "대한민국의 수도는 어디야?"
서울입니다.
```

`sgpt` 다음에 "현재 폴더 및 하위 폴더에 있는 모든 txt 파일을 보여주세요." 명령어를 보내면 이를 쉘 명령어로 변환한 후 유닉스 쉘 명령어를 제시하여 준다.

```bash
$ sgpt "현재 폴더 및 하위 폴더에 있는 모든 txt 파일을 보여주세요."
현재 폴더 및 하위 폴더에 있는 모든 txt 파일을 보여드리겠습니다. 아래 명령어를 입력해주세요.

find . -name "*.txt"
tidyverse@dl:/mnt/d/tcs/gpt-shell/shell-lesson-data$ find . -name "*.txt"
./exercise-data/numbers.txt
./exercise-data/writing/haiku.txt
./exercise-data/writing/LittleWomen.txt
./north-pacific-gyre/NENE01729A.txt
./north-pacific-gyre/NENE01729B.txt
./north-pacific-gyre/NENE01736A.txt
./north-pacific-gyre/NENE01751A.txt
./north-pacific-gyre/NENE01751B.txt
./north-pacific-gyre/NENE01812A.txt
./north-pacific-gyre/NENE01843A.txt
./north-pacific-gyre/NENE01843B.txt
./north-pacific-gyre/NENE01971Z.txt
./north-pacific-gyre/NENE01978A.txt
./north-pacific-gyre/NENE01978B.txt
./north-pacific-gyre/NENE02018B.txt
./north-pacific-gyre/NENE02040A.txt
./north-pacific-gyre/NENE02040B.txt
./north-pacific-gyre/NENE02040Z.txt
./north-pacific-gyre/NENE02043A.txt
./north-pacific-gyre/NENE02043B.txt
```

한단계 더 들어가 `-s` 매개변수를 제공하면 실행([E]xecute) 명령어 기술([D]escribe) 혹은 중단([A]bort)을 지정할 수 있다.

```bash
$ sgpt -s "현재 폴더 및 하위 폴더에 있는 모든 txt 파일을 보여주세요."
find . -name "*.txt"
[E]xecute, [D]escribe, [A]bort: D
Searches for all files with the extension ".txt" in the current directory and its subdirectories.
[E]xecute, [D]escribe, [A]bort: E
./exercise-data/numbers.txt
./exercise-data/writing/haiku.txt
./exercise-data/writing/LittleWomen.txt
./north-pacific-gyre/NENE01729A.txt
./north-pacific-gyre/NENE01729B.txt
./north-pacific-gyre/NENE01736A.txt
./north-pacific-gyre/NENE01751A.txt
./north-pacific-gyre/NENE01751B.txt
./north-pacific-gyre/NENE01812A.txt
./north-pacific-gyre/NENE01843A.txt
./north-pacific-gyre/NENE01843B.txt
./north-pacific-gyre/NENE01971Z.txt
./north-pacific-gyre/NENE01978A.txt
./north-pacific-gyre/NENE01978B.txt
./north-pacific-gyre/NENE02018B.txt
./north-pacific-gyre/NENE02040A.txt
./north-pacific-gyre/NENE02040B.txt
./north-pacific-gyre/NENE02040Z.txt
./north-pacific-gyre/NENE02043A.txt
./north-pacific-gyre/NENE02043B.txt
```

사용방법은 Git Bash를 설치한 후 터미널을 열고 `sgpt --shell` 혹은 `sgpt -s` 다음에 
자연어를 넣게 되면 해당되는 쉘 명령어를 알려준다.

이를 실행하게 되면 유닉스 쉘을 이용하여 해당 자동화 작업에 생산성을 높일 수 있다. 얼마전까지만 해도 한국어는 지원하지 않아 한글로 작성한 다음 번역기를 사용하여 영어로 입력해야 하고 결과를 얻게 되면 이를 실행하는 방식이 활용되었지만 지금은 유닉스 쉘 개념을 이해하여 한국어로 말을 풀어주게 되면 구현이 가능하다.


:::::{.columns}
:::{.column}

```bash
$ sgpt --shell 'List the contents of the current directory and display a special character at the end of each filename to indicate its file type.'
ls -F
[E]xecute, [D]escribe, [A]bort: E
goodiff.sh*      NENE01729B.txt*  NENE01751B.txt*  NENE01843B.txt*  NENE01978B.txt*  NENE02040B.txt*  NENE02043B.txt*
goostats.sh*     NENE01736A.txt*  NENE01812A.txt*  NENE01971Z.txt*  NENE02018B.txt*  NENE02040Z.txt*
NENE01729A.txt*  NENE01751A.txt*  NENE01843A.txt*  NENE01978A.txt*  NENE02040A.txt*  NENE02043A.txt*
```

:::

:::{.column}

```bash
$ sgpt -s '현재 디렉터리 콘텐츠를 나열하고 각 파일 이름 끝에 파일 유형을 나타내는 특수 문자를 표시합니다.'
ls -F
[E]xecute, [D]escribe, [A]bort: E
goodiff.sh*      NENE01729B.txt*  NENE01751B.txt*  NENE01843B.txt*  NENE01978B.txt*  NENE02040B.txt*  NENE02043B.txt*
goostats.sh*     NENE01736A.txt*  NENE01812A.txt*  NENE01971Z.txt*  NENE02018B.txt*  NENE02040Z.txt*
NENE01729A.txt*  NENE01751A.txt*  NENE01843A.txt*  NENE01978A.txt*  NENE02040A.txt*  NENE02043A.txt*
```
:::

:::::

## 실습 데이터 준비

실습데이터는 소프트웨어 카펜트리 유닉스 쉘 학습 페이지에서 직접 다운로드 받을 수 있다. \footnote{https://swcarpentry.github.io/shell-novice/data/shell-lesson-data.zip} WSL 우분투 혹은 데비안 쉘을 실행시켜 `cd` 명령어로 다음 디렉토리로 이동한다.

```bash
$ cd /mnt/c/users/사용자명/Desktop
```

`curl` 명령어로 `shell-lesson-data.zip`를 다운로드 받고 저장 파일명도 `-o` 옵션을 주고 동일한 `shell-lesson-data.zip` 파일명으로 바탕화면(Desktop)에 저장한다.

```bash
$  curl https://swcarpentry.github.io/shell-novice/data/shell-lesson-data.zip -o shell-lesson-data.zip
```

`unzip` 명령어로 `shell-lesson-data.zip` 파일 압축을 바탕화면(Desktop) 디렉토리에 `-d .` 선택옵션을 주어 작업을 실행한다.

```bash
$ unzip shell-lesson-data.zip -d .
```

`tree` 명령어로 디렉토리 구조만 `-d` 옵션을 주어 압축을 푼 `shell-lesson-data` 폴더 아래 구조를 확인한다.

```bash
$ tree -d shell-lesson-data
shell-lesson-data
├── exercise-data
│   ├── alkanes
│   ├── animal-counts
│   ├── creatures
│   └── writing
└── north-pacific-gyre

6 directories
```

:::{.callout-note}
## `-bash: tree: command not found`

`tree` 명령어를 실행할 수 없는 경우 다음 명령어로 패키지를 설치하여 문제를 해결한다.

```bash
$ sudo apt-get install tree
```

:::

## 챗GPT 활용사례

```{r}
#| echo: false
library(reticulate)

use_condaenv(condaenv = 'gpt-shell')
```

본서에서는 주로 작업 자동화와 관련된 챗GPT를 다루지만, OpenAI를 비롯한 다양한 대형 언어 모델(Language Large Model, LLM) 기반의 AI를 활용하여 다양한 자연어 처리 관련 업무를 수행할 수 있다. OpenAI의 환경 설정을 통해 유닉스 쉘 작업 자동화 외에도 챗GPT를 활용할 수 있는 업무에 대해 간략하게 살펴보겠다.

### 텍스트 완성

GPT를 이용하면 다양한 작업을 수행할 수 있지만, 가장 기본적인 작업은 글쓰기다. GPT는 생성형 AI로, 주어진 텍스트에 이어 나머지 텍스트를 최대 토큰 크기(max_tokens)만큼 생성해준다.\index{GPT} \index{openai!max\_tokens} \index{챗GPT}


```{python}
#| eval: false
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

complete_next = openai.Completion.create(
  model="text-davinci-003",
  prompt="나의 살던 고향은",
  max_tokens=7,
  temperature=0)
  
complete_next['choices'][0]['text']
```

```bash
'\n\n나의'
```


토큰 크기를 100으로 지정하면 제법 긴 텍스트를 출력한다. 영어 토큰에 최적화되어 있는 관계로 한글의 경우 토큰 낭비(?)가 심한 것으로 보인다. 고로 비용이 제법 나가는 점은 한국어로 작업을 할 때 고려해야만 된다.

```{python}
#| eval: false
complete_next_100 = openai.Completion.create(
  model="text-davinci-003",
  prompt="나의 살던 고향은",
  max_tokens=100,
  temperature=0)
  
complete_next_100['choices'][0]['text']
```

```bash
'\n\n나의 고향은 전라남도 여수시입니다. 여수는 전라남도의 동부에 위치한 해안 도시로'
```

### 키워드 추출

조금더 흥미로운 주제로 해당 문서를 제시하고 관련 텍스트의 주요 키워드\index{keywords}를 추출해보자. `Attention Is All You Need` 논문\cite{vaswani2017attention}은 AI 분야에서 획기적인 논문으로 평가받았지만 별도 키워드는 제시되고 있지 않아 논문 초록을 앞에 제시하고 `Keywords:`를 뒤에 두고 논문의 주요 키워드를 추출하게 한다.

```{python}
#| eval: false
prompt_keywords = "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n\n keywords:"

keywords = openai.Completion.create(
  model="text-davinci-003",
  prompt=prompt_keywords,
  temperature = 0.5,
  max_tokens  = 50)

keywords['choices'][0]['text']
```


`max_tokens`\index{openai!max\_tokens}을 50으로 제한하여 `temperature = 0.5`\index{openai!tempearature}로 너무 창의적이지 않게 키워드 추출 작업을 지시한 경우 다음과 같은 결과를 얻게 된다.



``` bash
'\nSequence transduction, neural networks, attention mechanisms, machine translation, parsing'
```


이번에는 한글 논문초록에서 키워드를 추출해보자. 2020년 출간된 논문\cite{Lee2020}의 한글 초록에서 제시된 키워드와 OpenAI GPT가 제시하고 있는 키워드와 비교해보자.

-   논문 소스코드: [바로가기](https://statkclee.github.io/comp_document/automation-kasdba.html)
-   PDF 출판 논문: [다운로드](https://statkclee.github.io/comp_document/data/00006_002_39.pdf)

```{python}
#| eval: false
prompt_keywords = "알파고가 2016년 바둑 인간 챔피언 이세돌 9단을 현격한 기량차이로 격파하면서 인공지능에 대한 관심이 급격히 증가하였다. 그와 동시에 기계가 인간의 일자리 잠식을 가속화하면서 막연한 불안감이 삽시간에 전파되었다. 기계와의 일자리 경쟁은 컴퓨터의 출현이전부터 시작되었지만 인간만의 고유한 영역으로 알고 있던 인지, 창작 등 다양한 분야에서 오히려 인간보다 더 우수한 성능과 저렴한 가격 경쟁력을 보여주면서 기존 인간의 일자리가 기계에 대체되는 것이 가시권에 들었다. 이번 문헌조사와 실증 데이터 분석을 통해서 기계가 인간의 일자리를 대체하는 자동화의 본질에 대해서 살펴보고, 인간과 기계의 업무 분장을 통해 더 생산성을 높일 수 있는 방안을 제시하고자 한다.\n\n 키워드:"

keywords = openai.Completion.create(
  model="text-davinci-003",
  prompt=prompt_keywords,
  temperature = 0.5,
  max_tokens  = 100)

keywords['choices'][0]['text']
```

```bash
' 인공지능, 자동화, 인간과 기계의 업무 분장, 생산성 \n\n이 문헌조사는 인공지능이 인'
```

GPT가 생성한 키워드를 논문저자가 추출한 키워드와 비교하면 다소 차이가 있지만 그래도 상위 3개 키워드는 높은 일치도를 보이고 있다.\index{자동화}\index{업무 분장}\index{키워드}

챗GPT 3.5 엔진으로 키워드를 추출할 경우 다소 매끄럽지 않게 한국어 키워드가 추출된 것도 확인된다. 이러한 문제는 GPT-4 버전 및 한국어 특화된 엔진을 사용할 경우 해소될 것으로 예상된다.


| OpenAI GPT 키워드 | 논문저자 추출 |
|-------------------|-------------------|
| - 인공지능           |-   자동화 |
| - 자동화           |-   데이터 과학|
| - 인간과 기계의 업무 분장           |-   인공지능|
| - 생산성이 문헌조사는 인공지능이 인'           |-   일자리 |
|                               | - 기계와 사람의 업무분장|


GPT-4는 더 높은 성능을 보여주고 있다. 해당 텍스트를 https://chat.openai.com/chat?model=gpt-4에 제공하면, 키워드를 추출하고 요약을 해준다.

![](images/completion_keywords.jpg){width="500"}


### 텍스트 요약

`Attention Is All You Need` 논문 초록은 <https://platform.openai.com/tokenizer> 계산기를 통해 230개 토큰 1,138 문자로 작성된 것이 확인된다. 
영어 기준으로 다음과 같은 맥락을 이해하고 이를 대략 20% 수준 50 토큰으로 줄여보자. 

- 100 토큰은 대략 75 단어
- 평균 단어는 대략 5 문자로 구성
- 100 토큰은 375개 문자

```{python}
#| eval: false
prompt_keywords = "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n\n summary:"

keywords = openai.Completion.create(
  model="text-davinci-003",
  prompt=prompt_keywords,
  temperature = 0.5,
  max_tokens  = 50)

keywords['choices'][0]['text']
```

상기 논문 초록을 50개 토큰으로 요약\index{요약}하면 다음과 같이 48개 토큰, 277 문자수로 요약해준다.

```bash
'\n\nThe Transformer is a new neural network architecture based solely on attention mechanisms, which is shown to outperform existing models on two machine translation tasks. It is more parallelizable and requires significantly less time to train than existing models, achieving a B'
```

### 여론조사 할일 생성

`TO-DO` 리스트를 제작하는 것은 해당 작업을 절차적으로 구분-정리하여 수행할 수 있게 되어 
해당 작업의 성공가능성을 높이고 생산성도 높일 수 있다.
여론조사\index{여론조사}를 한사람이 수행하는 경우는 거의 없지만 일반적으로 여론조사에서 수행할 일에 대해서 
지시명령어를 작성하여 결과를 살펴보자.


```{python}
#| eval: false

todo_list = openai.Completion.create(
  model="text-davinci-003",
  prompt="여론조사를 위해서 해야될 일을 작성하세요\n\n1.",
  temperature=0.3,
  max_tokens = 1000,
  top_p = 0.1,
  frequency_penalty=0,
  presence_penalty=0.5,
  stop=["6."]
)

todo_text = todo_list['choices'][0]['text']
```

```bash
' 여론조사 대상자를 선정하고, 여론조사 대상자의 수를 결정합니다.\n\n2. 여론조사 대상자들에게 여론조사 질문지를 배포합니다.\n\n3. 여론조사 대상자들에게 여론조사 응답을 요청합니다.\n\n4. 여론조사 응답을 수집하고, 분석합니다.\n\n5. 여론조사 결과를 보고서로 작성합니다.'
```

```{r}
#| eval: false
library(reticulate)
cat(glue::glue("1. {py$todo_text}"))
```

작업수행결과를 가독성 좋게 정리하면 다음과 같다.

1. 여론조사 대상자를 선정하고, 여론조사 대상자의 수를 결정합니다.
2. 여론조사 대상자들에게 여론조사 질문지를 배포합니다.
3. 여론조사 대상자들에게 여론조사 응답을 요청합니다.
4. 여론조사 응답을 수집하고, 분석합니다.
5. 여론조사 결과를 보고서로 작성합니다.


지금까지 OpenAI API를 사용하여 텍스트 자동생성기능을 활용하여 키워드 추출, 문서요약,
작업목록 생성과 같은 업무를 통해 가능성을 살펴봤다. 
이제 데이터 과학업무 생산성의 주요한 도구인 유닉스 쉘(Unix Shell)을  챗GPT로 
또 다른 데이터 과학의 세계로 나아가자.


\newpage

```{=tex}
\begin{Exercise}\label{Ex00}

\noindent 1. 실습 데이터를 준비하고 압축을 해제하는데 사용된 명령어는 무엇일까요?
\begin{tasks}[label=(\arabic*)](1)
\task cd
\task curl
\task unzip
\task 모두 사용됨
\end{tasks}

\noindent 2. 만약 `tree` 명령어를 실행할 수 없다면, 어떤 명령어를 사용하여 문제를 해결해야 합니까?

\noindent 3. 챗GPT 연동 과정에서 가상환경 구축에 사용되는 파이썬 모듈은 무엇일까요?
\begin{tasks}[label=(\arabic*)](1)
\task  virtualenv
\task  venv
\task  virtualenvwrapper
\task  모두 맞음
\end{tasks}

\noindent 4. OpenAI API Key를 저장하는 방식 중에서 어떤 파일에 지정하여 사용하면 버전 제어 대상에서 제외시켜야 하는 파일명은 무엇일까요?
\begin{tasks}[label=(\arabic*)](1)
\task  .env
\task  .gitignore
\task  .apikey
\task  apikey.txt
\end{tasks}

\noindent 5. API Key를 환경변수로 지정하여 사용하려면 윈도우에서 어디로 접근해야 하는가?
\begin{tasks}[label=(\arabic*)](1)
\task  시스템 환경 변수 설정
\task  API Key 관리
\task  프로젝트 설정
\task  환경변수.txt 파일 생성 및 저장
\end{tasks}

\noindent 6. 소프트웨어 카펜트리 유닉스 쉘에 사용되는 실습데이터를 `curl` 명령어로 다운로드 받아 압축을 풀어 `curl` 명령어로 저장을 한 후에 압축을 풀고 전체 디렉토리 구조를 일별합니다. 실습데이터는 소프트웨어 카펜트리 유닉스 쉘 학습 페이지에서 직접 다운로드 받을 수 있다. \footnote{https://swcarpentry.github.io/shell-novice/data/shell-lesson-data.zip}
`shell-lesson-data.zip` 압축을 풀고 폴더명은 shell-data 으로 지정합니다. 마지막으로, shell-data 아래 전체 디렉토리 구조만 나무형식으로 파일은 제외하고 보여주세요.

\noindent 7. 챗GPT를 사용하면 어떤 작업을 수행할 수 있을까요?

\begin{tasks}[label=(\arabic*)](1)
  \task 강화 학습 모델 훈련
  \task 음성 인식 시스템 구축
  \task 대화형 챗봇 개발
  \task 이미지 분류 알고리즘 개발
\end{tasks}

\noindent 8. 다음 중 GPT-4를 사용하여 자연어 처리에 어떻게 활용할 수 있는지 가장 적합하지 않은 예는 무엇일까요?

\begin{tasks}[label=(\arabic*)](1)
  \task  감성 분석
  \task  기계 번역
  \task  음성을 텍스트로 변환
  \task  문장 생성
\end{tasks}

\noindent 9. 챗GPT를 이용하여 불가능한 자연어 처리 작업은 무엇일까요?

\begin{tasks}[label=(\arabic*)](1)
  \task  텍스트 요약
  \task  텍스트 기반의 질의 응답
  \task  전문가 시스템을 위한 지식 표현
  \task  실시간 비디오 분석
\end{tasks}

\noindent 10. 챗GPT가 할 수 없는 자연어 처리 작업은 무엇일까요?

\begin{tasks}[label=(\arabic*)](1)
  \task  문장 교정
  \task  개체명 인식
  \task  독해 이해
  \task  특정 개인의 미래 행동 예측
\end{tasks}

\noindent 11. 다음 중 챗GPT를 활용한 챗봇 개발이 아닌 작업은 무엇일까요?

\begin{tasks}[label=(\arabic*)](1)
  \task  고객 지원 서비스 개발
  \task  대화형 게임 스크립트 작성
  \task  자동 완성 기능 개발
  \task  이미지 인식 시스템 개발
\end{tasks}


\end{Exercise}
```


